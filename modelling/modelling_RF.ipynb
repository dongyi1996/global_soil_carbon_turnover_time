{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc560584-4297-4f0f-914b-11207d55d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from sklearn import preprocessing, ensemble, metrics, linear_model, model_selection, inspection\n",
    "import datetime as dt\n",
    "from scipy import interpolate\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11ef7d-287b-4797-bd8d-4867820a02b0",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7bad28-ba1c-4fca-80a7-e41bb61d595f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46237, 7)\n",
      "['profile_id', 'latitude', 'longitude', 'biome_type', 'biome_type_name', 'tovr_0to30', 'tovr_30to100']\n",
      "\n",
      "['Tropical forests', 'Temperate forests', 'Boreal forests', 'Tropical savannahs and grasslands', 'Temperate grasslands and shrublands', 'Deserts', 'Tundra', 'Croplands']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/compiled_soc_turnover_sample_data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "print(list(df.columns))\n",
    "print()\n",
    "print(list(pd.Series(np.unique(df['biome_type_name'])).iloc[[5, 3, 0, 6, 4, 2, 7, 1]]))\n",
    "\n",
    "biome_name_list = ['Tropical forests', 'Temperate forests', 'Boreal forests', 'Tropical savannahs and grasslands', 'Temperate grasslands and shrublands', 'Deserts', 'Tundra', 'Croplands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b09e855-8072-444e-a137-f606c0cecd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_covar(df, df_covar, covar_name, on_key='profile_id'):\n",
    "    df_covar = df_covar[list(df_covar.columns)[:2]]\n",
    "    df_covar.columns = ['profile_id', covar_name]\n",
    "    df_merged = pd.merge(left=df, right=df_covar, on=on_key)\n",
    "    df_merged = df_merged.reset_index(drop=True)\n",
    "    return df_merged\n",
    "\n",
    "def get_soil_property_0to100(df_dir, soil_property_name):\n",
    "    df_samples_soil_property = pd.read_csv('{}/samples_{}_0-5cm_mean.csv'.format(df_dir, soil_property_name))\n",
    "    df_samples_soil_property.columns = list(df_samples_soil_property.columns)[:-1] + ['{}_0-5cm_mean'.format(soil_property_name)]\n",
    "    df_samples_soil_property = pd.merge(left=df_samples_soil_property, right=pd.read_csv('{}/samples_{}_5-15cm_mean.csv'.format(df_dir, soil_property_name)), on='profile_id')\n",
    "    df_samples_soil_property.columns = list(df_samples_soil_property.columns)[:-1] + ['{}_5-15cm_mean'.format(soil_property_name)]\n",
    "    df_samples_soil_property = pd.merge(left=df_samples_soil_property, right=pd.read_csv('{}/samples_{}_15-30cm_mean.csv'.format(df_dir, soil_property_name)), on='profile_id')\n",
    "    df_samples_soil_property.columns = list(df_samples_soil_property.columns)[:-1] + ['{}_15-30cm_mean'.format(soil_property_name)]\n",
    "    df_samples_soil_property = pd.merge(left=df_samples_soil_property, right=pd.read_csv('{}/samples_{}_30-60cm_mean.csv'.format(df_dir, soil_property_name)), on='profile_id')\n",
    "    df_samples_soil_property.columns = list(df_samples_soil_property.columns)[:-1] + ['{}_30-60cm_mean'.format(soil_property_name)]\n",
    "    df_samples_soil_property = pd.merge(left=df_samples_soil_property, right=pd.read_csv('{}/samples_{}_60-100cm_mean.csv'.format(df_dir, soil_property_name)), on='profile_id')\n",
    "    df_samples_soil_property.columns = list(df_samples_soil_property.columns)[:-1] + ['{}_60-100cm_mean'.format(soil_property_name)]\n",
    "\n",
    "    df_samples_soil_property['{}_pred_0to30'.format(soil_property_name)] = (df_samples_soil_property['{}_0-5cm_mean'.format(soil_property_name)] * 5 + df_samples_soil_property['{}_5-15cm_mean'.format(soil_property_name)] * 10 + df_samples_soil_property['{}_15-30cm_mean'.format(soil_property_name)] * 15) / 30.0\n",
    "    df_samples_soil_property['{}_pred_30to100'.format(soil_property_name)] = (df_samples_soil_property['{}_30-60cm_mean'.format(soil_property_name)] * 30 + df_samples_soil_property['{}_60-100cm_mean'.format(soil_property_name)] * 40) / 60.0\n",
    "    df_samples_soil_property = df_samples_soil_property[['profile_id', '{}_pred_0to30'.format(soil_property_name), '{}_pred_30to100'.format(soil_property_name)]]\n",
    "    return df_samples_soil_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59b4fd92-1343-439b-a338-b7d3865bdb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['profile_id', 'clay_0to30', 'clay_30to100', 'sand_0to30', 'sand_30to100', 'silt_0to30', 'silt_30to100', 'nitrogen_0to30', 'nitrogen_30to100', 'ph_0to30', 'ph_30to100', 'cec_0to30', 'cec_30to100']\n"
     ]
    }
   ],
   "source": [
    "df_samples_wosis = pd.read_csv('../datasets/covariates/wosis/samples_soil_properties.csv')\n",
    "print(list(df_samples_wosis.columns))\n",
    "df = pd.merge(left=df, right=df_samples_wosis, on='profile_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89ab569-da4b-4973-8d9c-2328369d35f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid data proportion <clay_0to30>: \t 88.9%\n",
      "Valid data proportion <clay_30to100>: \t 88.9%\n",
      "Valid data proportion <sand_0to30>: \t 74.6%\n",
      "Valid data proportion <sand_30to100>: \t 74.6%\n",
      "Valid data proportion <silt_0to30>: \t 88.0%\n",
      "Valid data proportion <silt_30to100>: \t 87.9%\n",
      "Valid data proportion <nitrogen_0to30>: \t 36.4%\n",
      "Valid data proportion <nitrogen_30to100>: \t 33.4%\n",
      "Valid data proportion <ph_0to30>: \t 89.0%\n",
      "Valid data proportion <ph_30to100>: \t 89.0%\n",
      "Valid data proportion <cec_0to30>: \t 42.4%\n",
      "Valid data proportion <cec_30to100>: \t 42.4%\n"
     ]
    }
   ],
   "source": [
    "for val_name in list(df_samples_wosis.columns[1:]):\n",
    "    print('Valid data proportion <{}>: \\t {:.1f}%'.format(val_name, 100*len(df[df[val_name] != -1]) / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2d011f-2eaf-4695-978d-90e436d6418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_soilgrid = '../datasets/covariates/soilgrid'\n",
    "\n",
    "soil_property_name = 'bdod'\n",
    "df_samples_bdod = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'cec'\n",
    "df_samples_cec = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'cfvo'\n",
    "df_samples_cfvo = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'clay'\n",
    "df_samples_clay = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'nitrogen'\n",
    "df_samples_nitrogen = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'ocd'\n",
    "df_samples_ocd = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'phh2o'\n",
    "df_samples_phh2o = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'sand'\n",
    "df_samples_sand = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'silt'\n",
    "df_samples_silt = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)\n",
    "\n",
    "soil_property_name = 'soc'\n",
    "df_samples_soc = get_soil_property_0to100(df_dir=dir_soilgrid, soil_property_name=soil_property_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c954c03-d355-45f9-95c5-c7c04daed285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df, right=df_samples_bdod, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_cec, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_cfvo, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_clay, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_nitrogen, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_ocd, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_phh2o, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_sand, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_silt, on='profile_id', how='left')\n",
    "df = pd.merge(left=df, right=df_samples_soc, on='profile_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ff32db-16e2-49d9-980e-05ffde3c63ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46237, 69)\n",
      "['profile_id', 'latitude', 'longitude', 'biome_type', 'biome_type_name', 'tovr_0to30', 'tovr_30to100', 'clay_0to30', 'clay_30to100', 'sand_0to30', 'sand_30to100', 'silt_0to30', 'silt_30to100', 'nitrogen_0to30', 'nitrogen_30to100', 'ph_0to30', 'ph_30to100', 'cec_0to30', 'cec_30to100', 'bdod_pred_0to30', 'bdod_pred_30to100', 'cec_pred_0to30', 'cec_pred_30to100', 'cfvo_pred_0to30', 'cfvo_pred_30to100', 'clay_pred_0to30', 'clay_pred_30to100', 'nitrogen_pred_0to30', 'nitrogen_pred_30to100', 'ocd_pred_0to30', 'ocd_pred_30to100', 'phh2o_pred_0to30', 'phh2o_pred_30to100', 'sand_pred_0to30', 'sand_pred_30to100', 'silt_pred_0to30', 'silt_pred_30to100', 'soc_pred_0to30', 'soc_pred_30to100', 'bio01', 'bio02', 'bio03', 'bio04', 'bio05', 'bio06', 'bio07', 'bio08', 'bio09', 'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17', 'bio18', 'bio19', 'aridity', 'elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi', 'evi', 'pop']\n"
     ]
    }
   ],
   "source": [
    "for bio_id in  ['bio01', 'bio02', 'bio03', 'bio04', 'bio05', 'bio06', 'bio07', 'bio08', 'bio09', 'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17', 'bio18', 'bio19']:\n",
    "    df_covar = pd.read_csv('../datasets/covariates/samples_{}.csv'.format(bio_id))\n",
    "    df = merge_covar(df=df, df_covar=df_covar, covar_name=bio_id, on_key='profile_id')\n",
    "\n",
    "df_covar = pd.read_csv('../datasets/covariates/samples_aridity.csv')\n",
    "df = merge_covar(df=df, df_covar=df_covar, covar_name='aridity', on_key='profile_id')\n",
    "\n",
    "for topo_varname in ['elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi']:\n",
    "    df_covar = pd.read_csv('../datasets/covariates/samples_{}.csv'.format(topo_varname))\n",
    "    df = merge_covar(df=df, df_covar=df_covar, covar_name=topo_varname, on_key='profile_id')\n",
    "\n",
    "df_covar = pd.read_csv('../datasets/covariates/samples_evi.csv')\n",
    "df = merge_covar(df=df, df_covar=df_covar, covar_name='evi', on_key='profile_id')\n",
    "\n",
    "df_covar = pd.read_csv('../datasets/covariates/samples_pop.csv')\n",
    "df = merge_covar(df=df, df_covar=df_covar, covar_name='pop', on_key='profile_id')\n",
    "\n",
    "print(df.shape)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca91e7bf-5bcb-4a2b-b55e-29c41b3c0664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_value(df, vname_target, vname_source, nodata_value=-1):\n",
    "    '''Replace the nodata values in the colume of 'target' with the values in the column of 'source'.\n",
    "    '''\n",
    "    if vname_target not in df.columns:\n",
    "        df[vname_target] = 0\n",
    "    val_new_list = []\n",
    "    val_src_list = list(df[vname_source])\n",
    "    for i in range(len(df)):\n",
    "        val_old = df[vname_target][i]\n",
    "        if val_old == nodata_value or val_old is None or np.isnan(val_old):\n",
    "            val_new = val_src_list[i]\n",
    "        else:\n",
    "            val_new = df[vname_target][i]\n",
    "        val_new_list.append(val_new)\n",
    "    df[vname_target] = val_new_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5995297d-0d60-49c9-aab0-4d9b67bbc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = replace_value(df=df, vname_target='clay_0to30', vname_source='clay_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='clay_30to100', vname_source='clay_pred_30to100', nodata_value=-1)\n",
    "\n",
    "df = replace_value(df=df, vname_target='sand_0to30', vname_source='clay_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='sand_30to100', vname_source='clay_pred_30to100', nodata_value=-1)\n",
    "\n",
    "df = replace_value(df=df, vname_target='silt_0to30', vname_source='clay_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='silt_30to100', vname_source='clay_pred_30to100', nodata_value=-1)\n",
    "\n",
    "df = replace_value(df=df, vname_target='cec_0to30', vname_source='cec_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='cec_30to100', vname_source='cec_pred_30to100', nodata_value=-1)\n",
    "\n",
    "df = replace_value(df=df, vname_target='ph_0to30', vname_source='phh2o_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='ph_30to100', vname_source='phh2o_pred_30to100', nodata_value=-1)\n",
    "\n",
    "df = replace_value(df=df, vname_target='nitrogen_0to30', vname_source='nitrogen_pred_0to30', nodata_value=-1)\n",
    "df = replace_value(df=df, vname_target='nitrogen_30to100', vname_source='nitrogen_pred_30to100', nodata_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc9d854-616e-4972-95fb-56665e74fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid data proportion <clay_0to30>: \t 100.0%\n",
      "Valid data proportion <clay_30to100>: \t 100.0%\n",
      "Valid data proportion <sand_0to30>: \t 100.0%\n",
      "Valid data proportion <sand_30to100>: \t 100.0%\n",
      "Valid data proportion <silt_0to30>: \t 100.0%\n",
      "Valid data proportion <silt_30to100>: \t 100.0%\n",
      "Valid data proportion <nitrogen_0to30>: \t 100.0%\n",
      "Valid data proportion <nitrogen_30to100>: \t 100.0%\n",
      "Valid data proportion <ph_0to30>: \t 100.0%\n",
      "Valid data proportion <ph_30to100>: \t 100.0%\n",
      "Valid data proportion <cec_0to30>: \t 100.0%\n",
      "Valid data proportion <cec_30to100>: \t 100.0%\n"
     ]
    }
   ],
   "source": [
    "for val_name in list(df_samples_wosis.columns[1:]):\n",
    "    print('Valid data proportion <{}>: \\t {:.1f}%'.format(val_name, 100*len(df[df[val_name] != -1]) / len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1aa3b-3007-4001-b565-291262b0f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../datasets/processed/df_samples_with_covariates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d149f73-53f8-41eb-9b18-c8ed615f2ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46237, 99)\n",
      "['profile_id', 'country_id', 'country_name', 'latitude', 'longitude', 'SOCS_0to30', 'SOCS_30to100', 'biome', 'biome_type_0', 'biome_type_name_0', 'landcover', 'landcover_prop', 'biome_type', 'biome_type_name', 'npp_modis', 'rmf', 'agb', 'bgb', 'smp', 'fbgb', 'frbnpp_0to30', 'frbnpp_30to100', 'agb_unc', 'bgb_unc', 'frbnpp_0to30_sd', 'frbnpp_30to100_sd', 'frbnpp_0to30_unc', 'frbnpp_30to100_unc', 'bnpp', 'tovr_0to30', 'tovr_30to100', 'tovr_0to30_log', 'tovr_30to100_log', 'tovr_sub2top', 'fbgb_sd', 'tovr_0to30_sd', 'tovr_30to100_sd', 'clay_0to30', 'clay_30to100', 'sand_0to30', 'sand_30to100', 'silt_0to30', 'silt_30to100', 'nitrogen_0to30', 'nitrogen_30to100', 'ph_0to30', 'ph_30to100', 'cec_0to30', 'cec_30to100', 'bdod_pred_0to30', 'bdod_pred_30to100', 'cec_pred_0to30', 'cec_pred_30to100', 'cfvo_pred_0to30', 'cfvo_pred_30to100', 'clay_pred_0to30', 'clay_pred_30to100', 'nitrogen_pred_0to30', 'nitrogen_pred_30to100', 'ocd_pred_0to30', 'ocd_pred_30to100', 'phh2o_pred_0to30', 'phh2o_pred_30to100', 'sand_pred_0to30', 'sand_pred_30to100', 'silt_pred_0to30', 'silt_pred_30to100', 'soc_pred_0to30', 'soc_pred_30to100', 'bio01', 'bio02', 'bio03', 'bio04', 'bio05', 'bio06', 'bio07', 'bio08', 'bio09', 'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17', 'bio18', 'bio19', 'aridity', 'elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi', 'evi', 'pop']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/processed/df_samples_with_covariates.csv')\n",
    "print(df.shape)\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7a199-3e36-4462-8931-0e41b9adf1fd",
   "metadata": {},
   "source": [
    "# Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1410fd1-392c-43af-a08f-c7905999b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_category_dict = {\n",
    "    'Climate':       ['aridity', 'bio01', 'bio02', 'bio03', 'bio04', 'bio05', 'bio06', 'bio07', 'bio08', 'bio09', 'bio10', 'bio11', 'bio12', 'bio13', 'bio14', 'bio15', 'bio16', 'bio17', 'bio18','bio19'],\n",
    "    'Soil_physical': ['clay_0to30', 'sand_0to30', 'silt_0to30', 'clay_30to100', 'sand_30to100', 'silt_30to100'],\n",
    "    'Soil_chemical': ['cec_0to30', 'nitrogen_0to30', 'ph_0to30', 'cec_30to100', 'nitrogen_30to100', 'ph_30to100'],\n",
    "    'Topography':    ['elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi']\n",
    "}\n",
    "\n",
    "color_category_dict = {\n",
    "    'Climate':       '#0080FF',\n",
    "    'Soil_physical': '#994C00',\n",
    "    'Soil_chemical': '#FF9933',\n",
    "    'Topography':    '#FF0000'\n",
    "}\n",
    "\n",
    "x_names_topsoil = [\n",
    "                   'elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi',\n",
    "                   'bio01', 'bio12',\n",
    "                   'cec_0to30', 'clay_0to30', 'nitrogen_0to30', 'ph_0to30', 'sand_0to30', 'silt_0to30',\n",
    "                  ]\n",
    "x_names_subsoil = [\n",
    "                   'elev', 'slp', 'cti', 'tri', 'vrm', 'roughness', 'tpi', 'spi',\n",
    "                   'bio01', 'bio12',\n",
    "                   'cec_30to100', 'clay_30to100', 'nitrogen_30to100', 'ph_30to100', 'sand_30to100', 'silt_30to100',\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30b37fe6-3f57-4051-b51e-a0bebce759da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_by_varname(var_name):\n",
    "    color = 'black'\n",
    "    for category in list(var_category_dict.keys()):\n",
    "        if var_name in var_category_dict[category]:\n",
    "            color = color_category_dict[category]\n",
    "            break\n",
    "    return color\n",
    "\n",
    "def data_sampling(df, sample_size=100, group_name='biome_type_name', rand_seed=314):\n",
    "    df_sampled = df.groupby(group_name, group_keys=False).apply(lambda x: x.sample(n=sample_size, random_state=rand_seed, replace=True)).reset_index(drop=True)\n",
    "    # print(df_sampled.groupby('biome_type_name').agg({'profile_id': 'count'}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]])\n",
    "    return df_sampled\n",
    "\n",
    "def data_sampling_by_weight(df, sample_size=100, weights_colname='sample_weight', rand_seed=314):\n",
    "    df_sampled = df.sample(n=sample_size, weights=weights_colname, replace=True, random_state=rand_seed).reset_index(drop=True)\n",
    "    # print(df_sampled.groupby('biome_type_name').agg({'profile_id': 'count'}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]])\n",
    "    return df_sampled\n",
    "\n",
    "def get_category_importance(var_names, importances):\n",
    "    df_category_importance = pd.DataFrame()\n",
    "    category_list = []\n",
    "    importance_list = []\n",
    "    summary_list = []\n",
    "    for category in list(var_category_dict.keys()):\n",
    "        var_list = var_category_dict[category]\n",
    "        importance_cate_list = []\n",
    "        importance_category = 0.0\n",
    "        for i in range(len(var_names)):\n",
    "            if var_names[i] in var_list:\n",
    "                importance_cate_list.append(importances[i])\n",
    "        if len(importance_cate_list) > 0:\n",
    "            importance_category = np.mean(importance_cate_list)\n",
    "            # importance_category = np.sum(importance_cate_list)\n",
    "        category_list.append(category)\n",
    "        importance_list.append(importance_category)\n",
    "    importance_list = [v / np.sum(importance_list) for v in importance_list]\n",
    "    for i in range(len(list(var_category_dict.keys()))):\n",
    "        category = list(var_category_dict.keys())[i]\n",
    "        summary_list.append('{} ({:.1f}%)'.format(category, importance_list[i]*100))\n",
    "    df_category_importance['category'] = category_list\n",
    "    df_category_importance['importance'] = importance_list\n",
    "    df_category_importance['summary'] = summary_list\n",
    "    return df_category_importance\n",
    "\n",
    "def calc_feat_importance(x, y, model=None, method='permutation', cv=5, rand_seed=314):\n",
    "    \"\"\"\n",
    "    method: 'normal' or 'permutation'\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = ensemble.RandomForestRegressor(n_estimators=100, random_state=rand_seed)\n",
    "    \n",
    "    if method == 'normal':\n",
    "        model.fit(x, y)\n",
    "        # y_pred = model.predict(x)\n",
    "        # r2 = metrics.r2_score(y, y_pred)\n",
    "        # print('R2_score = {:.3f}'.format(r2))\n",
    "        importances = model.feature_importances_\n",
    "        sorted_id_list = np.argsort(importances)[::-1]\n",
    "        sorted_x_names = [x_names[i] for i in sorted_id_list]\n",
    "        sorted_importances = [np.round(importances[i], 3) for i in sorted_id_list]\n",
    "    else:\n",
    "        importances = []\n",
    "        for cv_id in range(cv):\n",
    "            x_train, x_val, y_train, y_val = model_selection.train_test_split(x, y, test_size=0.25, random_state=rand_seed)\n",
    "            model.fit(x_train, y_train)\n",
    "            r = inspection.permutation_importance(model, x_val, y_val, n_repeats=5, n_jobs=8, random_state=0)\n",
    "            importances.append(list(r.importances_mean))\n",
    "        importances = np.mean(importances, axis=0)\n",
    "        sorted_id_list = np.argsort(importances)[::-1]\n",
    "        sorted_x_names_ = [x_names[i] for i in sorted_id_list]\n",
    "        sorted_importances_ = [np.round(importances[i], 3) for i in sorted_id_list]\n",
    "        sorted_x_names = []\n",
    "        sorted_importances = []\n",
    "        for i in range(len(sorted_importances_)):\n",
    "            if sorted_importances_[i] > 0:\n",
    "                sorted_x_names.append(sorted_x_names_[i])\n",
    "                sorted_importances.append(sorted_importances_[i])\n",
    "    \n",
    "    return sorted_x_names, sorted_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1e99c-e855-4958-adf1-3f49f7555666",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26bdac59-9225-49d6-9b0f-392a2c5b0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a column of sample weight depending on sample size within each biome\n",
    "weight_list = []\n",
    "for i in range(len(df)):\n",
    "    weight = 0\n",
    "    if df['biome_type_name'][i] == 'Tropical forests':\n",
    "        weight = 2\n",
    "    elif df['biome_type_name'][i] == 'Temperate forests':\n",
    "        weight = 1\n",
    "    elif df['biome_type_name'][i] == 'Boreal forests':\n",
    "        weight = 4\n",
    "    elif df['biome_type_name'][i] == 'Tropical savannahs and grasslands':\n",
    "        weight = 2\n",
    "    elif df['biome_type_name'][i] == 'Temperate grasslands and shrublands':\n",
    "        weight = 2\n",
    "    elif df['biome_type_name'][i] == 'Deserts':\n",
    "        weight = 2\n",
    "    elif df['biome_type_name'][i] == 'Tundra':\n",
    "        weight = 8\n",
    "    elif df['biome_type_name'][i] == 'Croplands':\n",
    "        weight = 1\n",
    "    else:\n",
    "        weight = 0\n",
    "    weight_list.append(weight)\n",
    "df['sample_weight'] = weight_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0fb48bd-47b2-4620-8be9-e988862c36ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     biome_type_name  tovr_0to30\n",
      "biome_type_name                                                 \n",
      "Tropical forests                                4206        45.0\n",
      "Temperate forests                              13469        56.0\n",
      "Boreal forests                                   557       146.0\n",
      "Tropical savannahs and grasslands               4949        41.0\n",
      "Temperate grasslands and shrublands             7132        57.0\n",
      "Deserts                                         2321        54.0\n",
      "Tundra                                           202       306.0\n",
      "Croplands                                      13401       103.0\n",
      "\n",
      "30978\n",
      "                                     biome_type_name  tovr_0to30\n",
      "biome_type_name                                                 \n",
      "Tropical forests                                3842        44.0\n",
      "Temperate forests                               6029        58.0\n",
      "Boreal forests                                  1023       139.0\n",
      "Tropical savannahs and grasslands               4497        40.0\n",
      "Temperate grasslands and shrublands             6588        56.0\n",
      "Deserts                                         2110        54.0\n",
      "Tundra                                           706       309.0\n",
      "Croplands                                       6183       102.0\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('biome_type_name', as_index=True).agg({'biome_type_name': 'count', 'tovr_0to30': np.mean, 'tovr_0to30': np.mean}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]].round(0))\n",
    "# df_resampled = data_sampling(df=df, sample_size=1000, group_name='biome_type_name', rand_seed=314)\n",
    "\n",
    "sample_size = int(len(df) * 0.67)\n",
    "df_resampled = data_sampling_by_weight(df=df, sample_size=sample_size, weights_colname='sample_weight', rand_seed=314)\n",
    "print()\n",
    "print(sample_size)\n",
    "print(df_resampled.groupby('biome_type_name', as_index=True).agg({'biome_type_name': 'count', 'tovr_0to30': np.mean, 'tovr_0to30': np.mean}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]].round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688b108-8065-4a9f-96c1-9239fbaf6aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_name = 'tovr_0to30_log'\n",
    "# y_name = 'tovr_30to100_log'\n",
    "# sample_size = 1000\n",
    "sample_size = int(len(df) * 0.67)\n",
    "print('sample_size: {}'.format(sample_size))\n",
    "rand_seed = 1024\n",
    "\n",
    "if '0to30' in y_name:\n",
    "    x_names = x_names_topsoil\n",
    "else:\n",
    "    x_names = x_names_subsoil\n",
    "\n",
    "df_ = df[[y_name] + x_names + ['biome_type_name'] + ['sample_weight']].dropna().reset_index(drop=True)\n",
    "df_[y_name] = np.power(10, df_[y_name])\n",
    "\n",
    "print(df_.groupby('biome_type_name', as_index=True).agg({'biome_type_name': 'count', y_name: np.mean, y_name: np.mean}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]].round(0))\n",
    "# df_ = data_sampling(df=df_, sample_size=sample_size, group_name='biome_type_name', rand_seed=314)\n",
    "df_ = data_sampling_by_weight(df=df_, sample_size=sample_size, weights_colname='sample_weight', rand_seed=3140)\n",
    "print(df_.groupby('biome_type_name', as_index=True).agg({'biome_type_name': 'count', y_name: np.mean, y_name: np.mean}).iloc[[5, 3, 0, 6, 4, 2, 7, 1]].round(0))\n",
    "print()\n",
    "\n",
    "x = np.array(df_[x_names])\n",
    "y = np.array(df_[y_name])\n",
    "# print(x.shape, y.shape)\n",
    "np.random.seed(rand_seed)\n",
    "model = ensemble.RandomForestRegressor(n_estimators=100, random_state=rand_seed)\n",
    "test_y = []\n",
    "test_y_pred = []\n",
    "biome_type_list = []\n",
    "shuffle_split = model_selection.ShuffleSplit(n_splits=10, test_size=0.1, random_state=314)\n",
    "r2_list = []\n",
    "for train_idx, test_idx in shuffle_split.split(x):\n",
    "    X_train, X_test = x[train_idx], x[test_idx]\n",
    "    Y_train, Y_test = y[train_idx], y[test_idx]\n",
    "    model.fit(X_train, Y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    r2 = metrics.r2_score(Y_test, y_test_pred)\n",
    "    print('R2_score = {:.3f}'.format(r2))\n",
    "    r2_list.append(r2)\n",
    "    test_y.extend(list(Y_test))\n",
    "    test_y_pred.extend(list(y_test_pred))\n",
    "    biome_type_list.extend(list(df_['biome_type_name'].iloc[test_idx]))\n",
    "\n",
    "print('R2_score_mean = {:.3f}'.format(np.mean(r2_list)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8bd51-2858-4bb2-945b-5c0aa4967eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res_samples_obspre = pd.DataFrame()\n",
    "# df_res_samples_obspre['obs'] = test_y\n",
    "# df_res_samples_obspre['pre'] = test_y_pred\n",
    "# df_res_samples_obspre['biome'] = biome_type_list\n",
    "# df_res_samples_obspre.to_csv('./results/df_res_samples_obs&pre_top.csv', index=False)\n",
    "# df_res_samples_obspre.to_csv('./results/df_res_samples_obs&pre_sub.csv', index=False)\n",
    "# df_res_samples_obspre.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
